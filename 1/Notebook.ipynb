{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "## a. Using variable elimination, calculate the probability that a student who did well on the exam understands the material.P(+u|+e). Show your work.\n",
    "\n",
    "P(+e) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Life expectancy</th>\n      <th>Adult Mortality</th>\n      <th>infant deaths</th>\n      <th>Alcohol</th>\n      <th>percentage expenditure</th>\n      <th>Hepatitis B</th>\n      <th>Measles</th>\n      <th>BMI</th>\n      <th>under-five deaths</th>\n      <th>Polio</th>\n      <th>Total expenditure</th>\n      <th>Diphtheria</th>\n      <th>HIV/AIDS</th>\n      <th>GDP</th>\n      <th>Population</th>\n      <th>thinness  1-19 years</th>\n      <th>thinness 5-9 years</th>\n      <th>Income composition of resources</th>\n      <th>Schooling</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2938.000000</td>\n      <td>2928.000000</td>\n      <td>2928.000000</td>\n      <td>2938.000000</td>\n      <td>2744.000000</td>\n      <td>2938.000000</td>\n      <td>2385.000000</td>\n      <td>2938.000000</td>\n      <td>2904.000000</td>\n      <td>2938.000000</td>\n      <td>2919.000000</td>\n      <td>2712.00000</td>\n      <td>2919.000000</td>\n      <td>2938.000000</td>\n      <td>2490.000000</td>\n      <td>2.286000e+03</td>\n      <td>2904.000000</td>\n      <td>2904.000000</td>\n      <td>2771.000000</td>\n      <td>2775.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2007.518720</td>\n      <td>69.224932</td>\n      <td>164.796448</td>\n      <td>30.303948</td>\n      <td>4.602861</td>\n      <td>738.251295</td>\n      <td>80.940461</td>\n      <td>2419.592240</td>\n      <td>38.321247</td>\n      <td>42.035739</td>\n      <td>82.550188</td>\n      <td>5.93819</td>\n      <td>82.324084</td>\n      <td>1.742103</td>\n      <td>7483.158469</td>\n      <td>1.275338e+07</td>\n      <td>4.839704</td>\n      <td>4.870317</td>\n      <td>0.627551</td>\n      <td>11.992793</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.613841</td>\n      <td>9.523867</td>\n      <td>124.292079</td>\n      <td>117.926501</td>\n      <td>4.052413</td>\n      <td>1987.914858</td>\n      <td>25.070016</td>\n      <td>11467.272489</td>\n      <td>20.044034</td>\n      <td>160.445548</td>\n      <td>23.428046</td>\n      <td>2.49832</td>\n      <td>23.716912</td>\n      <td>5.077785</td>\n      <td>14270.169342</td>\n      <td>6.101210e+07</td>\n      <td>4.420195</td>\n      <td>4.508882</td>\n      <td>0.210904</td>\n      <td>3.358920</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2000.000000</td>\n      <td>36.300000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.010000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.37000</td>\n      <td>2.000000</td>\n      <td>0.100000</td>\n      <td>1.681350</td>\n      <td>3.400000e+01</td>\n      <td>0.100000</td>\n      <td>0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2004.000000</td>\n      <td>63.100000</td>\n      <td>74.000000</td>\n      <td>0.000000</td>\n      <td>0.877500</td>\n      <td>4.685343</td>\n      <td>77.000000</td>\n      <td>0.000000</td>\n      <td>19.300000</td>\n      <td>0.000000</td>\n      <td>78.000000</td>\n      <td>4.26000</td>\n      <td>78.000000</td>\n      <td>0.100000</td>\n      <td>463.935626</td>\n      <td>1.957932e+05</td>\n      <td>1.600000</td>\n      <td>1.500000</td>\n      <td>0.493000</td>\n      <td>10.100000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2008.000000</td>\n      <td>72.100000</td>\n      <td>144.000000</td>\n      <td>3.000000</td>\n      <td>3.755000</td>\n      <td>64.912906</td>\n      <td>92.000000</td>\n      <td>17.000000</td>\n      <td>43.500000</td>\n      <td>4.000000</td>\n      <td>93.000000</td>\n      <td>5.75500</td>\n      <td>93.000000</td>\n      <td>0.100000</td>\n      <td>1766.947595</td>\n      <td>1.386542e+06</td>\n      <td>3.300000</td>\n      <td>3.300000</td>\n      <td>0.677000</td>\n      <td>12.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2012.000000</td>\n      <td>75.700000</td>\n      <td>228.000000</td>\n      <td>22.000000</td>\n      <td>7.702500</td>\n      <td>441.534144</td>\n      <td>97.000000</td>\n      <td>360.250000</td>\n      <td>56.200000</td>\n      <td>28.000000</td>\n      <td>97.000000</td>\n      <td>7.49250</td>\n      <td>97.000000</td>\n      <td>0.800000</td>\n      <td>5910.806335</td>\n      <td>7.420359e+06</td>\n      <td>7.200000</td>\n      <td>7.200000</td>\n      <td>0.779000</td>\n      <td>14.300000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2015.000000</td>\n      <td>89.000000</td>\n      <td>723.000000</td>\n      <td>1800.000000</td>\n      <td>17.870000</td>\n      <td>19479.911610</td>\n      <td>99.000000</td>\n      <td>212183.000000</td>\n      <td>87.300000</td>\n      <td>2500.000000</td>\n      <td>99.000000</td>\n      <td>17.60000</td>\n      <td>99.000000</td>\n      <td>50.600000</td>\n      <td>119172.741800</td>\n      <td>1.293859e+09</td>\n      <td>27.700000</td>\n      <td>28.600000</td>\n      <td>0.948000</td>\n      <td>20.700000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              Year  Life expectancy   Adult Mortality  infant deaths  \\\ncount  2938.000000       2928.000000      2928.000000    2938.000000   \nmean   2007.518720         69.224932       164.796448      30.303948   \nstd       4.613841          9.523867       124.292079     117.926501   \nmin    2000.000000         36.300000         1.000000       0.000000   \n25%    2004.000000         63.100000        74.000000       0.000000   \n50%    2008.000000         72.100000       144.000000       3.000000   \n75%    2012.000000         75.700000       228.000000      22.000000   \nmax    2015.000000         89.000000       723.000000    1800.000000   \n\n           Alcohol  percentage expenditure  Hepatitis B       Measles   \\\ncount  2744.000000             2938.000000  2385.000000    2938.000000   \nmean      4.602861              738.251295    80.940461    2419.592240   \nstd       4.052413             1987.914858    25.070016   11467.272489   \nmin       0.010000                0.000000     1.000000       0.000000   \n25%       0.877500                4.685343    77.000000       0.000000   \n50%       3.755000               64.912906    92.000000      17.000000   \n75%       7.702500              441.534144    97.000000     360.250000   \nmax      17.870000            19479.911610    99.000000  212183.000000   \n\n              BMI   under-five deaths         Polio  Total expenditure  \\\ncount  2904.000000         2938.000000  2919.000000         2712.00000   \nmean     38.321247           42.035739    82.550188            5.93819   \nstd      20.044034          160.445548    23.428046            2.49832   \nmin       1.000000            0.000000     3.000000            0.37000   \n25%      19.300000            0.000000    78.000000            4.26000   \n50%      43.500000            4.000000    93.000000            5.75500   \n75%      56.200000           28.000000    97.000000            7.49250   \nmax      87.300000         2500.000000    99.000000           17.60000   \n\n       Diphtheria      HIV/AIDS            GDP    Population  \\\ncount  2919.000000  2938.000000    2490.000000  2.286000e+03   \nmean     82.324084     1.742103    7483.158469  1.275338e+07   \nstd      23.716912     5.077785   14270.169342  6.101210e+07   \nmin       2.000000     0.100000       1.681350  3.400000e+01   \n25%      78.000000     0.100000     463.935626  1.957932e+05   \n50%      93.000000     0.100000    1766.947595  1.386542e+06   \n75%      97.000000     0.800000    5910.806335  7.420359e+06   \nmax      99.000000    50.600000  119172.741800  1.293859e+09   \n\n        thinness  1-19 years   thinness 5-9 years  \\\ncount            2904.000000          2904.000000   \nmean                4.839704             4.870317   \nstd                 4.420195             4.508882   \nmin                 0.100000             0.100000   \n25%                 1.600000             1.500000   \n50%                 3.300000             3.300000   \n75%                 7.200000             7.200000   \nmax                27.700000            28.600000   \n\n       Income composition of resources    Schooling  \ncount                      2771.000000  2775.000000  \nmean                          0.627551    11.992793  \nstd                           0.210904     3.358920  \nmin                           0.000000     0.000000  \n25%                           0.493000    10.100000  \n50%                           0.677000    12.300000  \n75%                           0.779000    14.300000  \nmax                           0.948000    20.700000  "
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "data = pd.read_csv(\"Life Expectancy Data.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(2938, 22)\nfiltered\n[[65.0 263.0 62 ... 17.3 0.479 10.1]\n [59.9 271.0 64 ... 17.5 0.47600000000000003 10.0]\n [59.9 268.0 66 ... 17.7 0.47 9.9]\n ...\n [44.8 73.0 25 ... 1.3 0.42700000000000005 10.0]\n [45.3 686.0 25 ... 1.7 0.42700000000000005 9.8]\n [46.0 665.0 24 ... 11.2 0.434 9.8]]\n[65.  59.9 59.9 ... 44.8 45.3 46. ]\narray([65. , 59.9, 59.9, ..., 44.8, 45.3, 46. ])\n[False False False ... False False False]\n"
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-50e35cb0af0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 492\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 758\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "# To find correlation of each variable perform linear regression in relation to each variable\n",
    "print(data.values.shape)\n",
    "filtered = data.values[:,:]\n",
    "print(\"filtered\")\n",
    "filtered=filtered[:,3:]\n",
    "print(filtered)\n",
    "for col in filtered.T:\n",
    "    col = col.astype(float)\n",
    "    col = np.array(col)\n",
    "    print(col.astype(float))\n",
    "    print(repr(col))\n",
    "    col = col[~np.isnan(col)]\n",
    "    print(np.isnan(col))\n",
    "    reg = LinearRegression().fit(col.reshape(-1,1), data.values[2:])\n",
    "    print(reg.score())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make model perform regresion on data set\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}